import pandas as pd
from langchain_community.vectorstores import DocArrayInMemorySearch
from langchain_community.llms import Ollama
from langchain_community.embeddings import OllamaEmbeddings
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders.csv_loader import CSVLoader


# Path to the CSV file
csv_file_path = "reviews1.csv"  # Update with your CSV file path

# Read CSV and drop specified columns
df = pd.read_csv(csv_file_path)
#df = df.drop(["User", "Rating", "Date", "Seller", "Likes"], axis=1)

# Save DataFrame to a CSV file
#df.to_csv("reviews1.csv", index=False)


loader = CSVLoader(file_path="reviews1.csv",encoding='utf-8')

data = loader.load()

print(data)

# Initialize components
MODEL = "llama3"
model = Ollama(model=MODEL)
embeddings = OllamaEmbeddings(model=MODEL)

# Initialize DocArrayInMemorySearch with the documents
vector_store = DocArrayInMemorySearch.from_documents(data, embedding=embeddings)
retriever = vector_store.as_retriever()


# Define the prompt template
template = """
Answer the question based on the context below. If you can't 
answer the question, reply "I don't know".

Context: {context}

Question: {question}
"""

prompt = PromptTemplate.from_template(template)

# Create the chain
from operator import itemgetter

chain = (
    {
        "context": itemgetter("question") | retriever,
        "question": itemgetter("question"),
    }
    | prompt
    | model
    | parser )

# Execute the chain
response = chain.invoke("Summarize the review below.")
print(response)

